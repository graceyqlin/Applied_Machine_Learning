{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification of Tweets About the Midterm Election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os,re,csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentiment', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'positive', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative']\n"
     ]
    }
   ],
   "source": [
    "# Set up input and output variables for the script\n",
    "midtermtweets = open(\"/Users/jasona/Downloads/data.csv\", \"r\")\n",
    " \n",
    "# Set up CSV reader and process the header\n",
    "csvReader = csv.reader(midtermtweets)\n",
    "\n",
    "# Get tweet text and sentiment\n",
    "tweettext = []\n",
    "sentiment = []\n",
    "# Loop through the lines in the file and get each coordinate\n",
    "for row in csvReader:\n",
    "    text = row[1]\n",
    "    affect = row[0]\n",
    "    tweettext.append(text)\n",
    "    sentiment.append(affect)\n",
    " \n",
    "# Print the coordinate list\n",
    "print sentiment\n",
    "\n",
    "midtermtweets.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter our Twitter credentials. These can be acquired through "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @nytimes: The New York Times needs your help. We\\xe2\\x80\\x99re looking for false information being spread deliberately to confuse, mislead, or infl\\xe2\\x80\\xa6'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT The New York Times needs your help We re looking for false information being spread deliberately to confuse mislead or infl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "\n",
    "cleantweets =[clean_tweet(tweet) for tweet in tweettext]\n",
    "\n",
    "cleantweets = cleantweets[1:] # Need to get rid of the headers\n",
    "\n",
    "cleantweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized\n",
    "# Divide into training and test\n",
    "# Training\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(cleantweets)\n",
    "X_counts.shape\n",
    "Labels = sentiment[1:]\n",
    "\n",
    "X_train = X_counts[0:60]\n",
    "Y_train = Labels[0:60]\n",
    "\n",
    "X_test = X_counts[60:]\n",
    "Y_test = Labels[60:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Train a multinomial Naive Bayes Classifier.\n",
    "2. Report Precision, Recall and F1 Statistics"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
