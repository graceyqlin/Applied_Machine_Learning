{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Topic Modeling and Natural Language Processing with Twitter Data\n",
    "\n",
    "##  Jason Anastasopoulos\n",
    "##  February 28, 2018\n",
    "### Email: ljanastas@princeton.edu\n",
    "\n",
    "The code below provides a brief introduction on acquiring Twitter data using the twitter API via Python. For this exercise I will be acquiring Donald Trump's tweets and will try to figure out what the topics his tweets are using the Latent Dirichlet Allocation  Topic Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os,re,csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter our Twitter credentials. These can be acquired through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Dec 19 19:38:51 +0000 2008\", \"description\": \"Microsoft Visiting Professor @PrincetonCITP\\u25aa\\ufe0fAssistant Professor @UGA_PA_Policy & Political Science \\u25aa\\ufe0f political economy\\u25aa\\ufe0f machine learning\\u25aa\\ufe0f causal inference\", \"favourites_count\": 779, \"followers_count\": 485, \"friends_count\": 532, \"geo_enabled\": true, \"id\": 18249358, \"id_str\": \"18249358\", \"lang\": \"en\", \"listed_count\": 33, \"location\": \"Princeton, NJ\", \"name\": \"Jason Anastasopoulos\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/561147677/sproul.jpg\", \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/561147677/sproul.jpg\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/18249358/1510588727\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/953308288044683264/pfRYpPeN_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/953308288044683264/pfRYpPeN_normal.jpg\", \"profile_link_color\": \"91D2FA\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"jlanastas\", \"status\": {\"created_at\": \"Mon Feb 26 17:52:22 +0000 2018\", \"favorited\": true, \"id\": 968181962014908416, \"id_str\": \"968181962014908416\", \"lang\": \"en\", \"retweet_count\": 192, \"retweeted\": true, \"retweeted_status\": {\"created_at\": \"Sun Feb 25 15:23:29 +0000 2018\", \"favorite_count\": 406, \"favorited\": true, \"id\": 967782105815142400, \"id_str\": \"967782105815142400\", \"lang\": \"en\", \"retweet_count\": 192, \"retweeted\": true, \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"Most common arguments against interpretable ML: \\n- Humans can't explain their actions either\\n- Performance &gt; Interp\\u2026 https://t.co/16rmCofp2t\", \"truncated\": true}, \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"RT @ChristophMolnar: Most common arguments against interpretable ML: \\n- Humans can't explain their actions either\\n- Performance &gt; Interpret\\u2026\"}, \"statuses_count\": 804, \"time_zone\": \"Eastern Time (US & Canada)\", \"url\": \"https://t.co/fBLr6MzlyV\", \"utc_offset\": -18000}\n"
     ]
    }
   ],
   "source": [
    "api = twitter.Api(consumer_key='mkz0izzVKDRzkrR4GoyN9FStT',\n",
    "                      consumer_secret='4A1YGFEixYmyUNf2idYC33GKCuFoyJkyKpQVXIXCpDedZe0nOt',\n",
    "                      access_token_key='18249358-xZGyGz8sWmQ9oJ1TBsLKEczwtO24aJ0Q4waDbjxAd',\n",
    "                      access_token_secret='uqH7cC5BLS65iuAEPEv4TXEtUZvFD80wH03xkqiB7SP7Y')\n",
    "\n",
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the Twitter API using keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970488599597600769, u'Congratulations @kobebryant!! More hardware for the Mamba. #Oscars https://t.co/3RY30WUYA6')\n",
      "(970489801576136704, u'Congratulations to the cast &amp; crew #PixarCoco on their Academy Award for Best Animated Feature! #Oscars https://t.co/EmRFd8ccCI')\n",
      "(970508113928269824, u'Amazing. \\n\\n#Oscars https://t.co/xoK6HBHM69')\n",
      "(970866438956253185, u'RT @mayatitos: Qu\\xe9 Eiza Gonz\\xe1lez en los #Oscars #Oscars90 te gusta m\\xe1s https://t.co/8VaoLfrKF9')\n",
      "(970866438952181760, u'RT @_AlexHirsch: Oh, so when *I* do a story about fish romance its no big deal, but when  @RealGDT does it, it\\u2019s Oscars ahoy! Where\\u2019s MY st\\u2026')\n",
      "(970866438800945152, u'RT @rdjcoldplay: in memory of jake gyllenhaal\\nhe ain\\u2019t dead, but the oscars like to pretend that he is #Oscars https://t.co/oUlqVrtsRs')\n",
      "(970866438578696192, u'RT @RealSteveRohr: #redcarpetready thanks to my new go-to @suitsupply! Impossible not to feel sharp in @suitsupply #tuxedo. Serious threads\\u2026')\n",
      "(970866438331232256, u'RT @BleacherReport: Amazing. \\n\\n#Oscars https://t.co/xoK6HBHM69')\n",
      "(970866438213963777, u'RT @shaidersolutt: melhor cena de drama vai para #oscars https://t.co/cRgYI6HucT')\n",
      "(970866438104866816, u'RT @ElJeringasLoko: \\xa1\\xa1\\xa1TOM\\xd3 LA P\\xd3CIMA, B\\xc9SALA Y\\xc1!!!  #Oscars https://t.co/R9zcVC8Vqa')\n",
      "(970866437337174016, u'RT @MarkMahon: And the winner is... #Oscars90  https://t.co/NZ3PvxhRxQ')\n",
      "(970866436502622208, u'RT @mitchellvii: If you BOYCOTTED the #OSCARS - Retweet! https://t.co/VbE0KMJLOr')\n",
      "(970866436322230272, u'RT @elgranqenk: Latinos DOMINAN los Oscars 2018: Del Toro - Mujer Fant\\xe1stica - Coco | SJS https://t.co/LELVeU7fWx')\n",
      "(970866436020359168, u\"RT @MarkDice: So Best Picture was given to a film about a woman who has sex with a reptile?  Well, we don't call Hollywood deviants for not\\u2026\")\n",
      "(970866435600904192, u'RT @ElGolGarracol: #Oscars \\n\\nLa Gran Estafa https://t.co/pdQJuLupzh')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = api.GetSearch(\"Oscars\") # Replace happy with your search\n",
    "for tweet in search:\n",
    "    print(tweet.id, tweet.text)\n",
    "    \n",
    "len(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python twitter library has a lot of cool functions that you can use and learn about through the help() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method GetUserTimeline in module twitter.api:\n",
      "\n",
      "GetUserTimeline(self, user_id=None, screen_name=None, since_id=None, max_id=None, count=None, include_rts=True, trim_user=False, exclude_replies=False) method of twitter.api.Api instance\n",
      "    Fetch the sequence of public Status messages for a single user.\n",
      "    \n",
      "    The twitter.Api instance must be authenticated if the user is private.\n",
      "    \n",
      "    Args:\n",
      "      user_id (int, optional):\n",
      "        Specifies the ID of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid user ID\n",
      "        is also a valid screen name.\n",
      "      screen_name (str, optional):\n",
      "        Specifies the screen name of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid screen\n",
      "        name is also a user ID.\n",
      "      since_id (int, optional):\n",
      "        Returns results with an ID greater than (that is, more recent\n",
      "        than) the specified ID. There are limits to the number of\n",
      "        Tweets which can be accessed through the API. If the limit of\n",
      "        Tweets has occurred since the since_id, the since_id will be\n",
      "        forced to the oldest ID available.\n",
      "      max_id (int, optional):\n",
      "        Returns only statuses with an ID less than (that is, older\n",
      "        than) or equal to the specified ID.\n",
      "      count (int, optional):\n",
      "        Specifies the number of statuses to retrieve. May not be\n",
      "        greater than 200.\n",
      "      include_rts (bool, optional):\n",
      "        If True, the timeline will contain native retweets (if they\n",
      "        exist) in addition to the standard stream of tweets.\n",
      "      trim_user (bool, optional):\n",
      "        If True, statuses will only contain the numerical user ID only.\n",
      "        Otherwise a full user object will be returned for each status.\n",
      "      exclude_replies (bool, optional)\n",
      "        If True, this will prevent replies from appearing in the returned\n",
      "        timeline. Using exclude_replies with the count parameter will mean you\n",
      "        will receive up-to count tweets - this is because the count parameter\n",
      "        retrieves that many tweets before filtering out retweets and replies.\n",
      "        This parameter is only supported for JSON and XML responses.\n",
      "    \n",
      "    Returns:\n",
      "      A sequence of Status instances, one for each message up to count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(api.GetUserTimeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = api.GetUserTimeline(screen_name=\"realDonaldTrump\", count=5000)\n",
    "tweets = [i.AsDict() for i in t]\n",
    "\n",
    "tweettext = [i[\"text\"] for i in tweets]\n",
    "\n",
    "len(tweettext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the text data which are all referenda in New Mexico from 2000-2014. Splits referenda using \"####\" demarcation, extracts each bill and places it into a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## So far so good not lets clean this up ###\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are pre-processing the text by creating a tokenizer that splits the documents up into tokens (words or phrases), creating a dictionary of stop words and creating a \"stemmer\" which stems the words (ie removing \"-ing\" endings etc. We also remove extraneous \"bill related\" words such as \"propXX_XXXX\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'march',\n",
       " u'5th',\n",
       " u'democrat',\n",
       " u'nowher',\n",
       " u'found',\n",
       " u'daca',\n",
       " u'gave',\n",
       " u'month',\n",
       " u'just',\n",
       " u'don',\n",
       " u'care',\n",
       " u'co',\n",
       " u'vucavygcb7']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tweettext:\n",
    "    #print \"Processing\",i\n",
    "    # clean and tokenize document string\n",
    "    tokens = tokenizer.tokenize(i)\n",
    "    # remove all numbers\n",
    "    tokens = [x for x in tokens if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "    # remove structural words\n",
    "    tokens = [x for x in tokens if len(x) > 1]\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    tokens = [x for x in tokens if 'http' not in x]\n",
    "    tokens = [x for x in tokens if x not in \"_\"]\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "dictionaryall = corpora.Dictionary(texts)\n",
    "\n",
    "corpusall = [dictionaryall.doc2bow(text) for text in texts]\n",
    "\n",
    "texts[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'It\\u2019s March 5th and the Democrats are nowhere to be found on DACA. Gave them 6 months, they just don\\u2019t care. Where a\\u2026 https://t.co/VuCAvyGCb7'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs tokenization, stop word removal and number removal and places the corpora into a clean list that will be ready for analysis using the Latent Dirichlet Allocation. \n",
    "\n",
    "Notice that there are two sets of texts that are jointly modeled \"commercetexts\" which are the \"business friendly\" Chamber of Commerce bills and \"nmtexts\" which are the New Mexico state referenda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate LDA model\n",
    "ldamodelall = gensim.models.ldamodel.LdaModel(corpusall, num_topics=5, id2word = dictionaryall, passes=20,\n",
    "                                              minimum_probability=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above estimates a 5 topic topic model using Trump's tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.032*\"co\" + 0.012*\"just\" + 0.009*\"nation\" + 0.007*\"daca\" + 0.007*\"great\"'), (1, u'0.048*\"co\" + 0.012*\"presid\" + 0.011*\"democrat\" + 0.010*\"elect\" + 0.009*\"great\"'), (2, u'0.051*\"co\" + 0.017*\"will\" + 0.013*\"today\" + 0.010*\"peopl\" + 0.007*\"republican\"'), (3, u'0.051*\"co\" + 0.007*\"rt\" + 0.007*\"daca\" + 0.007*\"fake\" + 0.006*\"news\"'), (4, u'0.050*\"co\" + 0.020*\"great\" + 0.009*\"today\" + 0.007*\"honor\" + 0.007*\"state\"')]\n"
     ]
    }
   ],
   "source": [
    "# First 25 are the Chamber of Commerce Bills Remaining are the propositions so...\n",
    "\n",
    "print(ldamodelall.print_topics(num_topics=5, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the first 5 topics from the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code extracts the topic proportion distributions from the joint Chamber of Commerce and New Mexico referendum model and plots the topic proprtions for one Chamber of Commerce bill (top) and one New Mexico referendum."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
