{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Topic Modeling and Natural Language Processing with Twitter Data\n",
    "\n",
    "##  Jason Anastasopoulos\n",
    "##  April 2nd 2018\n",
    "### Email: ljanastas@princeton.edu\n",
    "\n",
    "The code below provides a brief introduction on acquiring Twitter data using the twitter API via Python. For this exercise I will be acquiring Donald Trump's tweets and will try to figure out what the topics his tweets are using the Latent Dirichlet Allocation  Topic Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os,re,csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter our Twitter credentials. These can be acquired through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Dec 19 19:38:51 +0000 2008\", \"description\": \"Microsoft Visiting Professor @PrincetonCITP\\u25aa\\ufe0fAssistant Professor @UGA_PA_Policy & Political Science \\u25aa\\ufe0f political economy\\u25aa\\ufe0f machine learning\\u25aa\\ufe0f causal inference\", \"favourites_count\": 798, \"followers_count\": 486, \"friends_count\": 541, \"geo_enabled\": true, \"id\": 18249358, \"id_str\": \"18249358\", \"lang\": \"en\", \"listed_count\": 33, \"location\": \"Princeton, NJ\", \"name\": \"Jason Anastasopoulos\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/561147677/sproul.jpg\", \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/561147677/sproul.jpg\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/18249358/1510588727\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/953308288044683264/pfRYpPeN_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/953308288044683264/pfRYpPeN_normal.jpg\", \"profile_link_color\": \"91D2FA\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"jlanastas\", \"status\": {\"created_at\": \"Wed Mar 21 19:43:55 +0000 2018\", \"favorite_count\": 1, \"id\": 976544958047014914, \"id_str\": \"976544958047014914\", \"in_reply_to_screen_name\": \"arthur_spirling\", \"in_reply_to_status_id\": 976531672786235392, \"in_reply_to_user_id\": 4646611941, \"lang\": \"en\", \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"@arthur_spirling Spot on. I've been working on some projects involving Empirical Bayes and have been complicit in suppressing it.\"}, \"statuses_count\": 812, \"time_zone\": \"Eastern Time (US & Canada)\", \"url\": \"https://t.co/fBLr6MzlyV\", \"utc_offset\": -14400}\n"
     ]
    }
   ],
   "source": [
    "api = twitter.Api(consumer_key='mkz0izzVKDRzkrR4GoyN9FStT',\n",
    "                      consumer_secret='4A1YGFEixYmyUNf2idYC33GKCuFoyJkyKpQVXIXCpDedZe0nOt',\n",
    "                      access_token_key='18249358-xZGyGz8sWmQ9oJ1TBsLKEczwtO24aJ0Q4waDbjxAd',\n",
    "                      access_token_secret='uqH7cC5BLS65iuAEPEv4TXEtUZvFD80wH03xkqiB7SP7Y')\n",
    "\n",
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the Twitter API using keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976316028010426368, u\"This is the theater where the Oscars were held. No offense to Hollywood's best &amp; brightest, but I think we had a be\\u2026 https://t.co/ZhUjHWbeQH\")\n",
      "(976324353821429762, u'Carol Kane at the 1976 Oscars is a real mood https://t.co/oF4rzToGUE')\n",
      "(975918392136802304, u'Would @TiffanyHaddish be the next host for the #Oscars? \\n\\nShe shares her thoughts at the #TwitterHouse at #SXSW.\\u2026 https://t.co/KxkCMtUcvh')\n",
      "(976616349442199552, u'RT @TwitterTV: Would @TiffanyHaddish be the next host for the #Oscars? \\n\\nShe shares her thoughts at the #TwitterHouse at #SXSW. #PayTheLady\\u2026')\n",
      "(976616345956683781, u'RT @rilaws: Carol Kane at the 1976 Oscars is a real mood https://t.co/oF4rzToGUE')\n",
      "(976616310057656320, u'RT @GMA: WAKANDA FOREVER! @chadwickboseman brings a bit of @theblackpanther to the #Oscars red carpet! https://t.co/6YJWYVSrEb https://t.co\\u2026')\n",
      "(976616273940566017, u'RT @VinceSchilling: Friday on Native Trailblazers Radio\\n\\n\"The Real Story Behind the #Oscars Moment\" \\nAn Interview with Sacheen Littlefeathe\\u2026')\n",
      "(976616170789982208, u'RT @keiynanick: nick robinson swept the 2019 oscars with this line delivery alone https://t.co/E8QHY0HsCz')\n",
      "(976616032004595712, u\"RT @mishacollins: This is the theater where the Oscars were held. No offense to Hollywood's best &amp; brightest, but I think we had a better a\\u2026\")\n",
      "(976615912664129537, u'@jimmykimmel to @kobebryant : you have won more #oscars than @SHAQ and @michaelb4jordan put together!!')\n",
      "(976615830514520064, u'OK Sports Fans...  Name The 1961 Movie Starring Mickey Rooney, George Peppard, and Audrey Hepburn. Hint: A Couple o\\u2026 https://t.co/1fySkQPSxT')\n",
      "(976615707046830081, u'Memes de Elza Gonzalez en los Oscars 2018 https://t.co/JyDH2OC1mT #FelizMiercoles')\n",
      "(976615690974117888, u'RT @MatthiasCamenz1: Guillermo del Toro\\'s \"The Shape of Water\" emerged as the big winner at the 90th Oscars on Sunday night. Having been no\\u2026')\n",
      "(976615648389410821, u'RT @Lupita_Nyongo: Power Pose. #Oscars https://t.co/Wa7eqHlb46')\n",
      "(976615529522847744, u'RT @TwitterTV: Would @TiffanyHaddish be the next host for the #Oscars? \\n\\nShe shares her thoughts at the #TwitterHouse at #SXSW. #PayTheLady\\u2026')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = api.GetSearch(\"Oscars\") # Replace happy with your search\n",
    "for tweet in search:\n",
    "    print(tweet.id, tweet.text)\n",
    "    \n",
    "len(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python twitter library has a lot of cool functions that you can use and learn about through the help() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method GetUserTimeline in module twitter.api:\n",
      "\n",
      "GetUserTimeline(self, user_id=None, screen_name=None, since_id=None, max_id=None, count=None, include_rts=True, trim_user=False, exclude_replies=False) method of twitter.api.Api instance\n",
      "    Fetch the sequence of public Status messages for a single user.\n",
      "    \n",
      "    The twitter.Api instance must be authenticated if the user is private.\n",
      "    \n",
      "    Args:\n",
      "      user_id (int, optional):\n",
      "        Specifies the ID of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid user ID\n",
      "        is also a valid screen name.\n",
      "      screen_name (str, optional):\n",
      "        Specifies the screen name of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid screen\n",
      "        name is also a user ID.\n",
      "      since_id (int, optional):\n",
      "        Returns results with an ID greater than (that is, more recent\n",
      "        than) the specified ID. There are limits to the number of\n",
      "        Tweets which can be accessed through the API. If the limit of\n",
      "        Tweets has occurred since the since_id, the since_id will be\n",
      "        forced to the oldest ID available.\n",
      "      max_id (int, optional):\n",
      "        Returns only statuses with an ID less than (that is, older\n",
      "        than) or equal to the specified ID.\n",
      "      count (int, optional):\n",
      "        Specifies the number of statuses to retrieve. May not be\n",
      "        greater than 200.\n",
      "      include_rts (bool, optional):\n",
      "        If True, the timeline will contain native retweets (if they\n",
      "        exist) in addition to the standard stream of tweets.\n",
      "      trim_user (bool, optional):\n",
      "        If True, statuses will only contain the numerical user ID only.\n",
      "        Otherwise a full user object will be returned for each status.\n",
      "      exclude_replies (bool, optional)\n",
      "        If True, this will prevent replies from appearing in the returned\n",
      "        timeline. Using exclude_replies with the count parameter will mean you\n",
      "        will receive up-to count tweets - this is because the count parameter\n",
      "        retrieves that many tweets before filtering out retweets and replies.\n",
      "        This parameter is only supported for JSON and XML responses.\n",
      "    \n",
      "    Returns:\n",
      "      A sequence of Status instances, one for each message up to count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(api.GetUserTimeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u201cSpecial Council is told to find crimes, whether a crime exists or not. I was opposed to the selection of Mueller t\\u2026 https://t.co/KYsOPqiVBG',\n",
       " u'...there was no probable cause for believing that there was any crime, collusion or otherwise, or obstruction of ju\\u2026 https://t.co/zZFkhcS0jf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = api.GetUserTimeline(screen_name=\"realDonaldTrump\", count=5000)\n",
    "tweets = [i.AsDict() for i in t]\n",
    "\n",
    "tweettext = [i[\"text\"] for i in tweets]\n",
    "\n",
    "tweettext[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the text data which are all referenda in New Mexico from 2000-2014. Splits referenda using \"####\" demarcation, extracts each bill and places it into a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## So far so good not lets clean this up ###\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are pre-processing the text by creating a tokenizer that splits the documents up into tokens (words or phrases), creating a dictionary of stop words and creating a \"stemmer\" which stems the words (ie removing \"-ing\" endings etc. We also remove extraneous \"bill related\" words such as \"propXX_XXXX\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'can',\n",
       " u'help',\n",
       " u'solv',\n",
       " u'problem',\n",
       " u'north',\n",
       " u'korea',\n",
       " u'syria',\n",
       " u'ukrain',\n",
       " u'isi',\n",
       " u'iran',\n",
       " u'even',\n",
       " u'come',\n",
       " u'arm',\n",
       " u'race',\n",
       " u'bush',\n",
       " u'co',\n",
       " u'hrz6vrjjvc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tweettext:\n",
    "    #print \"Processing\",i\n",
    "    # clean and tokenize document string\n",
    "    tokens = tokenizer.tokenize(i)\n",
    "    # remove all numbers\n",
    "    tokens = [x for x in tokens if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "    # remove structural words\n",
    "    tokens = [x for x in tokens if len(x) > 1]\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    tokens = [x for x in tokens if 'http' not in x]\n",
    "    tokens = [x for x in tokens if x not in \"_\"]\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "dictionaryall = corpora.Dictionary(texts)\n",
    "\n",
    "corpusall = [dictionaryall.doc2bow(text) for text in texts]\n",
    "\n",
    "texts[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'depart',\n",
       " u'justic',\n",
       " u'urg',\n",
       " u'suprem',\n",
       " u'court',\n",
       " u'least',\n",
       " u'hear',\n",
       " u'driver',\n",
       " u'licens',\n",
       " u'case',\n",
       " u'illeg',\n",
       " u'immi',\n",
       " u'co',\n",
       " u'teayq9in3t']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'.....They can help solve problems with North Korea, Syria, Ukraine, ISIS, Iran and even the coming Arms Race. Bush\\u2026 https://t.co/hrZ6vrJjVC'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs tokenization, stop word removal and number removal and places the corpora into a clean list that will be ready for analysis using the Latent Dirichlet Allocation. \n",
    "\n",
    "Notice that there are two sets of texts that are jointly modeled \"commercetexts\" which are the \"business friendly\" Chamber of Commerce bills and \"nmtexts\" which are the New Mexico state referenda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate LDA model\n",
    "ldamodelall = gensim.models.ldamodel.LdaModel(corpusall, num_topics=7, id2word = dictionaryall, passes=20,\n",
    "                                              minimum_probability=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above estimates a 5 topic topic model using Trump's tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, u'0.041*\"co\" + 0.018*\"great\" + 0.012*\"countri\" + 0.012*\"will\" + 0.009*\"meet\"'), (1, u'0.038*\"co\" + 0.008*\"better\" + 0.008*\"collus\" + 0.008*\"today\" + 0.006*\"much\"'), (5, u'0.060*\"co\" + 0.018*\"job\" + 0.012*\"trade\" + 0.011*\"thank\" + 0.008*\"year\"'), (4, u'0.043*\"co\" + 0.015*\"great\" + 0.011*\"north\" + 0.011*\"korea\" + 0.009*\"just\"'), (2, u'0.050*\"co\" + 0.015*\"will\" + 0.011*\"state\" + 0.011*\"foxnew\" + 0.009*\"just\"')]\n"
     ]
    }
   ],
   "source": [
    "# 5 topics from Trump's tweets derived from the top 5 words\n",
    "\n",
    "print(ldamodelall.print_topics(num_topics=5, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the first 5 topics from the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Topic 1: \"great\" + 0.012*\"countri\" + 0.012*\"will\" + 0.009*\"meet\"' - Diplomatic Relations\n",
    "- Topic 2: \"better\" + 0.008*\"collus\" + 0.008*\"today\" + 0.006*\"much\"' -  Russia Special Investigation\n",
    "- Topic 3: \"job\" + 0.012*\"trade\" + 0.011*\"thank\" + 0.008*\"year\"' - Economy\n",
    "- Topic 4: 0.015*\"great\" + 0.011*\"north\" + 0.011*\"korea\" + 0.009*\"just\"' - North Korea\n",
    "- Topic 5: 0.015*\"will\" + 0.011*\"state\" + 0.011*\"foxnew\" + 0.009*\"just\"' - Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the topic distribution for each tweet. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
